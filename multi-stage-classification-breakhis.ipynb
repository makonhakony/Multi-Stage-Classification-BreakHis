{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":999617,"sourceType":"datasetVersion","datasetId":209316},{"sourceId":235,"sourceType":"modelInstanceVersion","modelInstanceId":163}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nThis notebook aim to improve efficiency and reduce overfitting of Breast Cancer classification by Simple Data Augmentation and Compact CNN Architecture.\n\n# About the Dataset and Method\nEach image filename stores information about the image itself: method of procedure biopsy, tumor class, tumor type, patient identification, and magnification factor. For example, SOB_B_TA-14-4659-40-001.png is the image 1, at magnification factor **40X**, of a benign tumor of type tubular adenoma, original from the slide 14-4659, which was collected by procedure SOB.\n\nUsing Tensorflow","metadata":{}},{"cell_type":"markdown","source":"# Helper","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow\n!pip install -q -U tensorflow_addons","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:27:29.707110Z","iopub.execute_input":"2024-07-11T08:27:29.707478Z","iopub.status.idle":"2024-07-11T08:27:54.070407Z","shell.execute_reply.started":"2024-07-11T08:27:29.707449Z","shell.execute_reply":"2024-07-11T08:27:54.069135Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"model_handle_map = {\n    \"efficientnetv2-s\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/1\",\n    \"efficientnetv2-m\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_m/feature_vector/1\",\n    \"efficientnetv2-l\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_l/feature_vector/1\",\n    \"efficientnetv2-s-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_s/feature_vector/1\",\n    \"efficientnetv2-m-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_m/feature_vector/1\",\n    \"efficientnetv2-l-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_l/feature_vector/1\",\n    \"efficientnetv2-s-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_s/feature_vector/1\",\n    \"efficientnetv2-m-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_m/feature_vector/1\",\n    \"efficientnetv2-l-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_l/feature_vector/1\",\n    \"efficientnetv2-b0\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\",\n    \"efficientnetv2-b1\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b1/feature_vector/1\",\n    \"efficientnetv2-b2\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b2/feature_vector/1\",\n    \"efficientnetv2-b3\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b3/feature_vector/1\",\n    \"efficientnet_b0\": \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\",\n    \"efficientnet_b1\": \"https://tfhub.dev/tensorflow/efficientnet/b1/feature-vector/1\",\n    \"efficientnet_b2\": \"https://tfhub.dev/tensorflow/efficientnet/b2/feature-vector/1\",\n    \"efficientnet_b3\": \"https://tfhub.dev/tensorflow/efficientnet/b3/feature-vector/1\",\n    \"efficientnet_b4\": \"https://tfhub.dev/tensorflow/efficientnet/b4/feature-vector/1\",\n    \"efficientnet_b5\": \"https://tfhub.dev/tensorflow/efficientnet/b5/feature-vector/1\",\n    \"efficientnet_b6\": \"https://tfhub.dev/tensorflow/efficientnet/b6/feature-vector/1\",\n    \"efficientnet_b7\": \"https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1\",\n    \"bit_s-r50x1\": \"https://tfhub.dev/google/bit/s-r50x1/1\",\n    \"inception_v3\": \"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4\",\n    \"inception_resnet_v2\": \"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature-vector/4\",\n    \"resnet_v1_50\": \"https://tfhub.dev/google/imagenet/resnet_v1_50/feature-vector/4\",\n    \"resnet_v1_101\": \"https://tfhub.dev/google/imagenet/resnet_v1_101/feature-vector/4\",\n    \"resnet_v1_152\": \"https://tfhub.dev/google/imagenet/resnet_v1_152/feature-vector/4\",\n    \"resnet_v2_50\": \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\",\n    \"resnet_v2_101\": \"https://tfhub.dev/google/imagenet/resnet_v2_101/feature_vector/5\",\n    \"resnet_v2_152\": \"https://tfhub.dev/google/imagenet/resnet_v2_152/feature-vector/4\",\n    \"nasnet_large\": \"https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/4\",\n    \"nasnet_mobile\": \"https://tfhub.dev/google/imagenet/nasnet_mobile/feature_vector/4\",\n    \"pnasnet_large\": \"https://tfhub.dev/google/imagenet/pnasnet_large/feature_vector/4\",\n    \"mobilenet_v2_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n    \"mobilenet_v2_130_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/feature_vector/4\",\n    \"mobilenet_v2_140_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\",\n    \"mobilenet_v3_small_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\",\n    \"mobilenet_v3_small_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5\",\n    \"mobilenet_v3_large_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\",\n    \"mobilenet_v3_large_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/feature_vector/5\",\n}\n\n\nmodel_image_size_map = {\n    \"efficientnetv2-s\": 384,\n    \"efficientnetv2-m\": 480,\n    \"efficientnetv2-l\": 480,\n    \"efficientnetv2-s-21k\": 384,\n    \"efficientnetv2-m-21k\": 480,\n    \"efficientnetv2-l-21k\": 480,\n    \"efficientnetv2-s-21k-ft1k\": 384,\n    \"efficientnetv2-m-21k-ft1k\": 480,\n    \"efficientnetv2-l-21k-ft1k\": 480,\n    \"efficientnetv2-b0\": 224,\n    \"efficientnetv2-b1\": 240,\n    \"efficientnetv2-b2\": 260,\n    \"efficientnetv2-b3\": 300,\n    \"efficientnet_b0\": 224,\n    \"efficientnet_b1\": 240,\n    \"efficientnet_b2\": 260,\n    \"efficientnet_b3\": 300,\n    \"efficientnet_b4\": 380,\n    \"efficientnet_b5\": 456,\n    \"efficientnet_b6\": 528,\n    \"efficientnet_b7\": 600,\n    \"inception_v3\": 299,\n    \"inception_resnet_v2\": 299,\n    \"nasnet_large\": 331,\n    \"pnasnet_large\": 331,\n}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-11T08:22:49.411043Z","iopub.execute_input":"2024-07-11T08:22:49.411375Z","iopub.status.idle":"2024-07-11T08:22:49.425100Z","shell.execute_reply.started":"2024-07-11T08:22:49.411346Z","shell.execute_reply":"2024-07-11T08:22:49.422431Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"kaggle_path = '../input/breakhis/'\nimg_path = 'BreaKHis_v1/'","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.426239Z","iopub.execute_input":"2024-07-11T08:22:49.426525Z","iopub.status.idle":"2024-07-11T08:22:49.475216Z","shell.execute_reply.started":"2024-07-11T08:22:49.426504Z","shell.execute_reply":"2024-07-11T08:22:49.474336Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Support function","metadata":{}},{"cell_type":"code","source":"def plot_count_data(col_name):\n    df = pd.DataFrame(data, columns=[col_name])\n\n    # Count the occurrences of each label\n    label_counts = df[col_name].value_counts()\n\n    # Plot the counts\n    plt.figure(figsize=(6, 4))\n    plt.bar(label_counts.index, label_counts.values, color=['cyan', 'violet'])\n    plt.xlabel(col_name)\n    plt.ylabel('Count')\n    plt.title('Counts of '+ col_name +' in the samples')\n    plt.xticks([0, 1], label_counts.index)\n    plt.show()\n\n    print(label_counts)\n\ndef view_image():\n    pass\n\ndef build_compact_network(image_size):\n    print('building model...')\n    model = tf.keras.Sequential([\n        layers.InputLayer(input_shape=(image_size, image_size, 3)),\n        hub.KerasLayer(model_handle, trainable=True, name='base_model'),\n        layers.Dense(512, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.5),\n        layers.Dense(128, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dense(1, activation='sigmoid', name='classifier') \n    ],name=model_name)\n    model.build((None, image_size, image_size, 3))\n    model.summary()\n    print('model loaded!!!')\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.477589Z","iopub.execute_input":"2024-07-11T08:22:49.477871Z","iopub.status.idle":"2024-07-11T08:22:49.487637Z","shell.execute_reply.started":"2024-07-11T08:22:49.477849Z","shell.execute_reply":"2024-07-11T08:22:49.486684Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Init Notebook","metadata":{}},{"cell_type":"code","source":"import sys\nprint(sys.version)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.488665Z","iopub.execute_input":"2024-07-11T08:22:49.488929Z","iopub.status.idle":"2024-07-11T08:22:49.501142Z","shell.execute_reply.started":"2024-07-11T08:22:49.488907Z","shell.execute_reply":"2024-07-11T08:22:49.500255Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import library","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom tensorflow import keras\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\n# from tensorflow.keras.models import model\nfrom tensorflow.keras.layers import Input\nimport tensorflow_addons as tfa\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport albumentations as A\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:26:33.514217Z","iopub.execute_input":"2024-07-11T08:26:33.514646Z","iopub.status.idle":"2024-07-11T08:26:33.634313Z","shell.execute_reply.started":"2024-07-11T08:26:33.514615Z","shell.execute_reply":"2024-07-11T08:26:33.633156Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# from tensorflow.keras.models import model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpimg\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow_addons/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m _check_tf_version()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Local project imports\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow_addons/activations/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Additional activation functions.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgelu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhardshrink\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hardshrink\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlisht\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lisht\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow_addons/activations/gelu.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorLike\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mregister_keras_serializable(package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddons\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgelu\u001b[39m(x: TensorLike, approximate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gaussian Error Linear Unit.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Computes gaussian error linear:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        A `Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/types.py:56\u001b[0m\n\u001b[1;32m     54\u001b[0m Constraint \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mstr\u001b[39m, Callable, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mconstraints\u001b[38;5;241m.\u001b[39mConstraint]\n\u001b[1;32m     55\u001b[0m Activation \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mstr\u001b[39m, Callable]\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtensorflow.keras.optimizers.legacy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     Optimizer \u001b[38;5;241m=\u001b[39m Union[\n\u001b[1;32m     58\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mOptimizer, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mOptimizer, \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/importlib/util.py:94\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     92\u001b[0m parent_name \u001b[38;5;241m=\u001b[39m fullname\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parent_name:\n\u001b[0;32m---> 94\u001b[0m     parent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparent_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfromlist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m__path__\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m         parent_path \u001b[38;5;241m=\u001b[39m parent\u001b[38;5;241m.\u001b[39m__path__\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.optimizers'"],"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow.keras.optimizers'","output_type":"error"}]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\ndata = pd.read_csv('../input/breakhis/Folds.csv')\nimg_dir = '../input/breakhis/BreaKHis_v1/'\nclass_names = ['benign', 'malignant']\n\n#load from CSV File\ndata = data.rename(columns={'filename':'path'})\ndata['label'] = data.path.apply(lambda x: x.split('/')[3])\ndata['label_int'] = data.label.apply(lambda x: class_names.index(x))\ndata['filename'] = data.path.apply(lambda x: x.split('/')[-1])\ndata.head(3)\n#path = data.filename.apply(lambda x: x.split('/')[3])","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.675107Z","iopub.status.idle":"2024-07-11T08:22:49.675469Z","shell.execute_reply.started":"2024-07-11T08:22:49.675294Z","shell.execute_reply":"2024-07-11T08:22:49.675309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Dataset","metadata":{}},{"cell_type":"code","source":"plot_count_data('label')\n\nplot_count_data('grp')","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.676692Z","iopub.status.idle":"2024-07-11T08:22:49.677068Z","shell.execute_reply.started":"2024-07-11T08:22:49.676896Z","shell.execute_reply":"2024-07-11T08:22:49.676911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"benign_paths = data[data['label'] == 'benign']['path'][:10]\nmalignant_paths = data[data['label'] == 'malignant']['path'][:10]\n\n\nfig, axs = plt.subplots(2, 10, figsize=(15, 5))\nfor i, path in enumerate(benign_paths):\n    img = plt.imread(kaggle_path + img_path + path)\n    axs[0, i].imshow(img)\n    axs[0, i].axis('off')\n    axs[0, i].set_title(f'Benign {i+1}')\n\nfor i, path in enumerate(malignant_paths):\n    img = plt.imread(kaggle_path + img_path + path)\n    axs[1, i].imshow(img)\n    axs[1, i].axis('off')\n    axs[1, i].set_title(f'Malignant {i+1}')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.678703Z","iopub.status.idle":"2024-07-11T08:22:49.679167Z","shell.execute_reply.started":"2024-07-11T08:22:49.678935Z","shell.execute_reply":"2024-07-11T08:22:49.678954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From non-professional biologist like me Benign looks like Rib Eyes and Malignant looks like Chuck Steak 😂","metadata":{}},{"cell_type":"markdown","source":"# Preprocess Data","metadata":{}},{"cell_type":"code","source":"model_name = 'efficientnetv2-b0'\nmodel_handle = model_handle_map.get(model_name)\nIMAGE_SIZE = model_image_size_map.get(model_name, 224)\nBATCH_SIZE = 64\nEPOCHS = 12\n\nprint(f\"Selected model: {model_name} : {model_handle}\")\nprint(f\"Input size {IMAGE_SIZE}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.680118Z","iopub.status.idle":"2024-07-11T08:22:49.680549Z","shell.execute_reply.started":"2024-07-11T08:22:49.680327Z","shell.execute_reply":"2024-07-11T08:22:49.680345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1) Train and Val df splitting:\nSplit Train and Validation set to 80% and 20% of original Traing set accordingly","metadata":{}},{"cell_type":"code","source":"# Todo: reduce the column name\ndf_train, df_val = train_test_split(\n    data[data['grp'] == 'train'], \n    train_size=0.8, \n    shuffle=True\n)\n\nSAMPLE_SIZE = len(df_train)\n\nprint(len(df_train),len(df_val))","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.681990Z","iopub.status.idle":"2024-07-11T08:22:49.682432Z","shell.execute_reply.started":"2024-07-11T08:22:49.682189Z","shell.execute_reply":"2024-07-11T08:22:49.682207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2) Data Augmentation on Traing set","metadata":{}},{"cell_type":"code","source":"def parse_image(path, label):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_png(img, channels=3)\n    return img, label\n\ndef aug_fn(image): \n    transforms = A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.Rotate(p=0.5, limit=15),\n        A.RandomBrightnessContrast(p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.1, 0.1), brightness_by_max=True),\n        A.RandomResizedCrop(p=0.8, height=IMAGE_SIZE, width=IMAGE_SIZE, scale=(0.9, 1.1), ratio=(0.05, 1.1), interpolation=0),\n        A.Blur(p=0.3, blur_limit=(1, 1)),\n    ])\n    data = {\"image\":image}\n    aug_data = transforms(**data)\n    aug_img = aug_data[\"image\"]\n    aug_img = tf.cast(aug_img, tf.float32)\n    aug_img = tf.image.resize(aug_img, [IMAGE_SIZE, IMAGE_SIZE])/255\n    return aug_img\n\ndef augmentor(image, label):\n    aug_img = tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\n    return aug_img, label","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.684138Z","iopub.status.idle":"2024-07-11T08:22:49.684576Z","shell.execute_reply.started":"2024-07-11T08:22:49.684354Z","shell.execute_reply":"2024-07-11T08:22:49.684372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset After Augmentation","metadata":{}},{"cell_type":"code","source":"def resize_rescale(image, label):\n    img = tf.cast(image, tf.float32)\n    img = tf.image.resize(img, [IMAGE_SIZE, IMAGE_SIZE])/255\n    return img, label\n\ntrain_loader = tf.data.Dataset.from_tensor_slices((img_dir+df_train.path, df_train.label_int))\nvalid_loader = tf.data.Dataset.from_tensor_slices((img_dir+df_val.path, df_val.label_int))\n\ntrain_ds = (\n    train_loader.shuffle(len(df_train))\n    .map(parse_image, num_parallel_calls=AUTOTUNE)\n    .map(partial(augmentor),num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE) \n)\nvalid_ds = (\n    valid_loader.shuffle(len(df_val))\n    .map(parse_image, num_parallel_calls=AUTOTUNE)\n    .map(resize_rescale, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.686093Z","iopub.status.idle":"2024-07-11T08:22:49.686410Z","shell.execute_reply.started":"2024-07-11T08:22:49.686252Z","shell.execute_reply":"2024-07-11T08:22:49.686265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define (Compact?) Model","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nprint('building model...')\nmodel = tf.keras.Sequential([\n    layers.InputLayer(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n    hub.KerasLayer(model_handle, trainable=True, name='base_model'),\n    layers.Dense(512, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dense(1, activation='sigmoid', name='classifier') \n],name=model_name)\nmodel.build((None, IMAGE_SIZE, IMAGE_SIZE, 3))\nmodel.summary()\nprint('model loaded!!!')","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.687368Z","iopub.status.idle":"2024-07-11T08:22:49.687678Z","shell.execute_reply.started":"2024-07-11T08:22:49.687524Z","shell.execute_reply":"2024-07-11T08:22:49.687537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"## Define Learning Rate Model","metadata":{}},{"cell_type":"code","source":"def custom_lr_schedule(epoch, initial_lr=2e-1, maximal_lr=7e-3, step_size=3):\n    cycle = 1 + epoch // (2 * step_size)\n    x = abs(epoch / step_size - 2 * cycle + 1)\n    lr = initial_lr + (maximal_lr - initial_lr) * max(0, 1 - x)\n    return lr\n\ninitial_learning_rate = 2e-1\nmaximal_learning_rate = 7e-3\nstep_size = 3 * (SAMPLE_SIZE // BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.688664Z","iopub.status.idle":"2024-07-11T08:22:49.689113Z","shell.execute_reply.started":"2024-07-11T08:22:49.688884Z","shell.execute_reply":"2024-07-11T08:22:49.688902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n\nMETRICS = [\n    'accuracy',\n    tf.keras.metrics.Precision(name='precision'),\n    tf.keras.metrics.Recall(name='recall'),\n]\n# Default optimizer\n# clr_scheduler = tfa.optimizers.CyclicalLearningRate( \n#     initial_learning_rate=2e-1,  maximal_learning_rate=7e-3, \n#     step_size=3*(SAMPLE_SIZE//BATCH_SIZE),  \n#     scale_fn=lambda x: 1 / (2.0 ** (x - 1)), \n#     scale_mode='cycle'\n# )\n\n# model.compile(\n#     optimizer=tf.keras.optimizers.SGD(learning_rate=clr_scheduler) , \n#     loss=tf.keras.losses.BinaryCrossentropy(), \n#     metrics=METRICS\n# )\n\n# Custom optimizer\n\nlearningrate_cb = tf.keras.callbacks.LearningRateScheduler(custom_lr_schedule)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.SGD(learning_rate=initial_learning_rate) , \n    loss=tf.keras.losses.BinaryCrossentropy(), \n    metrics=METRICS\n)\n\nhistory = model.fit(\n    train_ds, \n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    verbose=1,\n    callbacks = [checkpoint_cb, learningrate_cb],\n#     callbacks = [checkpoint_cb],\n    validation_data=valid_ds,\n)\ntraining_history(history.history)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.690409Z","iopub.status.idle":"2024-07-11T08:22:49.690881Z","shell.execute_reply.started":"2024-07-11T08:22:49.690625Z","shell.execute_reply":"2024-07-11T08:22:49.690645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating","metadata":{}},{"cell_type":"code","source":"test_df = test_df.sample(frac=1).reset_index(drop=True)\ntest_ds = tf.data.Dataset.from_tensor_slices(img_dir+test_df.path) \ntest_ds = test_ds.map(decode_test,num_parallel_calls=AUTOTUNE).batch(len(test_df))\ntest_img = next(iter(test_ds))\ntest_index = test_df.label_int.values\ntest_label = test_df.label.values\n\ntest_pred = model.predict(test_ds)\npred_index = np.round(test_pred).astype('uint8')\npred_label = np.array(class_names)[pred_index]\n\nprint(classification_report(test_index, pred_index, target_names=class_names,zero_division=0))\nprint('f1_score        :', f1_score(test_index, pred_index, average='micro'))\nprint('accuracy_score  :', accuracy_score(test_index, pred_index))\n\ncm = skplt.metrics.plot_confusion_matrix(test_label, pred_label, figsize=(8, 8), normalize=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.692124Z","iopub.status.idle":"2024-07-11T08:22:49.692566Z","shell.execute_reply.started":"2024-07-11T08:22:49.692339Z","shell.execute_reply":"2024-07-11T08:22:49.692358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inferencing","metadata":{}},{"cell_type":"code","source":"prediction_df = pd.DataFrame({'filename':test_df.filename.values,'actual':test_df.label.values, 'prediction': np.squeeze(pred_label),'path':test_df.path.values,})\nwrong_df = prediction_df[prediction_df.actual != prediction_df.prediction].reset_index(drop=True)\n\n#view first 30 prediction\nplt.figure(figsize=(25,8))\nplt.rcParams.update({'font.size': 8})\nplt.subplots_adjust(wspace=0.05, hspace=0.15)\nfor i in range(30):\n    ax = plt.subplot(3, 10, i + 1)\n    shape = str(test_img[i].numpy().shape)\n    plt.imshow(test_img[i].numpy())\n    plt.title(pred_label[i][0])\n    plt.axis(\"off\") \n    plt.tight_layout","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:22:49.694216Z","iopub.status.idle":"2024-07-11T08:22:49.694532Z","shell.execute_reply.started":"2024-07-11T08:22:49.694378Z","shell.execute_reply":"2024-07-11T08:22:49.694391Z"},"trusted":true},"execution_count":null,"outputs":[]}]}